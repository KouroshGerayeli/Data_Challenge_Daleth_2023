{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VCE5hIeqhbW6","outputId":"7e3c4571-61fe-44de-ac25-01319c3609c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"i0z9US7vherr","outputId":"0d0ca982-fbe2-4c61-d806-ac7b98d54042"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/dataset_1.zip'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}],"source":["import shutil\n","\n","# Specify the source file path in your Colab environment\n","source_file_path = '/content/drive/MyDrive/DataChallenge/dataset_1.zip'\n","\n","# Specify the destination file path in your Google Drive\n","destination_file_path = '/content/dataset_1.zip'\n","\n","# Copy the file from the source path to the destination path\n","shutil.copyfile(source_file_path, destination_file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g05ivXXkDzuK","outputId":"f8f33b4c-5ca8-4133-aa63-ed1bd546ad96"},"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  dataset_1.zip\n","   creating: dataset_1/\n","   creating: dataset_1/OK/\n","  inflating: dataset_1/OK/CH214FC2_342055_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342060_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342064_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342077_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342171_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342173_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342175_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342177_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342179_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342182_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342186_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342188_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342190_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342194_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342202_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342325_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342328_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342330_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342332_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342338_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342341_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342347_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342406_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342410_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342417_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342419_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342485_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342488_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342614_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342619_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342622_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342625_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342628_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342632_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342636_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342641_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342644_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342649_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342654_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342656_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342661_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342665_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342679_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342681_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342683_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342696_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342702_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342707_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342715_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342721_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342753_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342757_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342761_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342770_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342781_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342792_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342798_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342806_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_342811_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343042_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343050_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343069_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343259_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343264_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343272_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343285_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343290_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343298_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343301_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343308_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343317_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343326_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343560_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343565_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343572_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343576_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343582_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343594_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343607_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343798_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343812_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343830_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343835_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343857_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_343865_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_344278_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_344289_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_344294_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_344303_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_344307_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_344319_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_344968_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_344972_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_344984_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_344989_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_344996_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_345001_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_345005_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_345830_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/OK/CH214FC2_345836_0_RESPONSIVITE_3.png  \n","   creating: dataset_1/Vague/\n","  inflating: dataset_1/Vague/CH214FC2_333125_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_339714_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_339717_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_340220_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_341260_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_342058_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_342068_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_342070_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_342072_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_342336_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_342608_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_342609_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_342612_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_342688_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_342690_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_342692_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_343062_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_343281_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_343846_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_343850_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_343851_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_343861_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_343867_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_343870_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC2_344991_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_359464_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_359466_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_360785_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_360808_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_360814_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_360819_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_360824_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_360950_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_361091_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_361097_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_362019_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_362023_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_362031_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_362040_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_362046_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_362422_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_364268_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_364275_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_364390_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_364774_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_364779_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_365098_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_365274_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_365296_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_365375_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_365427_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_365736_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_365837_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_365916_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_366200_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_366309_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_366951_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_366955_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_366970_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_367080_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_367113_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_367183_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_367308_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_367792_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_367797_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_368372_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_368398_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_368401_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_368653_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_368658_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_368779_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_368783_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_368794_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_368799_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369208_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369217_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369235_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369365_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369365_3_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369366_2_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369368_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369369_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369371_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369371_3_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369372_2_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369378_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369380_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369384_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369392_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369394_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369401_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369411_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369461_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369464_1_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369467_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369467_2_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369472_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369486_0_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369490_2_RESPONSIVITE_3.png  \n","  inflating: dataset_1/Vague/CH214FC3_369882_1_RESPONSIVITE_3.png  \n"]}],"source":["!unzip dataset_1.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j1WNuhuSDyXS"},"outputs":[],"source":["# Importing libraries\n","import numpy as np\n","import os\n","import tensorflow as tf\n","import pathlib\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.applications.resnet import ResNet50\n","from tensorflow.keras.applications.xception import Xception\n","from tensorflow.keras.applications import InceptionResNetV2\n","from tensorflow.keras.applications import ResNet101, ResNet50\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from keras import Sequential, layers\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Dropout\n","from keras.optimizers import SGD\n","from keras.layers import Rescaling\n","import matplotlib.pyplot as plt\n","from keras.callbacks import EarlyStopping\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Lambda\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kU-xhYjUDyXU","outputId":"3925e1b2-4d8d-4a8a-9ec8-4f40be6be2a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 200 files belonging to 2 classes.\n","Using 160 files for training.\n","Found 200 files belonging to 2 classes.\n","Using 40 files for validation.\n"]}],"source":["# Specifications\n","batch_size = 16\n","img_height = 512\n","img_width = 640\n","\n","#Load dataset\n","file_dir = pathlib.Path('/content/dataset_1')\n","\n","\n","train_ds = tf.keras.utils.image_dataset_from_directory(\n","  file_dir,\n","  validation_split=0.2,\n","  subset=\"training\",\n","  image_size= (512, 640),\n","  label_mode = 'categorical',\n","  color_mode = \"grayscale\",\n","  seed = 457,\n","  batch_size=batch_size)\n","\n","val_ds = tf.keras.utils.image_dataset_from_directory(\n","  file_dir,\n","  validation_split=0.2,\n","  image_size= (512, 640),\n","  subset=\"validation\",\n","  label_mode = 'categorical',\n","  seed = 457,\n","  color_mode = \"grayscale\",\n","  batch_size=batch_size)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EEurN9HPrUXU","outputId":"0058c7bf-edd9-4391-a646-c5c3614aadda"},"outputs":[{"output_type":"stream","name":"stdout","text":["No common images between training and validation datasets.\n"]}],"source":["# Get the file names from the training dataset\n","train_filenames = [str(pathlib.Path(path).name) for path in train_ds.file_paths]\n","\n","# Get the file names from the validation dataset\n","val_filenames = [str(pathlib.Path(path).name) for path in val_ds.file_paths]\n","\n","# Convert the file names to sets\n","train_set = set(train_filenames)\n","val_set = set(val_filenames)\n","\n","# Find the intersection of the two sets\n","common_images = train_set.intersection(val_set)\n","\n","# Check if the intersection is empty\n","if len(common_images) == 0:\n","    print(\"No common images between training and validation datasets.\")\n","else:\n","    print(\"Common images found between training and validation datasets:\", common_images)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"mu6PWzO7DyXW","outputId":"1558f80e-ac0e-4be5-8356-23f5b714d656"},"outputs":[{"ename":"AttributeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-75-05c9c66b0b28>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Names of the classes and Visualization of the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'DirectoryIterator' object has no attribute 'class_names'"]}],"source":["# # Names of the classes and Visualization of the data\n","# class_names = train_generator.class_names\n","# print(class_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K5cn-Gz_DyXX","outputId":"a2ed6a53-8afa-4299-eeac-ddaf1d0ff7ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94765736/94765736 [==============================] - 5s 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"]}],"source":["# Load the pre-trained ResNet50 model\n","resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n","\n","# Freeze the pre-trained layers\n","for layer in resnet.layers:\n","    layer.trainable = False\n","\n","# Convert grayscale to RGB\n","def grayscale_to_rgb(image):\n","    return tf.image.grayscale_to_rgb(image)\n","\n","# Add new layers for your own dataset\n","inputs = tf.keras.Input(shape=(img_height, img_width, 1))\n","rgb_images = Lambda(grayscale_to_rgb)(inputs)\n","x = resnet(rgb_images)\n","x = Flatten()(x)\n","x = Dense(256, activation='relu')(x)\n","x = Dropout(0.25)(x)\n","x = Dense(256, activation='relu')(x)\n","x = Dropout(0.25)(x)\n","x = Dense(256,activation='relu')(x)\n","x = Dropout(0.25)(x)\n","predictions = Dense(2, activation='softmax')(x)\n","\n","# Create a new model\n","model = Model(inputs=inputs, outputs=predictions)\n","opt = tf.keras.optimizers.experimental.AdamW()\n","\n","def scheduler(epoch, lr):\n","   if epoch < 5:\n","     return lr\n","   else:\n","     return lr * tf.math.exp(-0.1)\n","callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n","# Compile the model\n","model.compile(optimizer= 'adam', loss='categorical_crossentropy', \n","              metrics=['accuracy'])\n","\n","\n","\n","\n","# Define the checkpoint path and format\n","checkpoint_path = \"model_checkpoint_{epoch:02d}.h5\"\n","\n","# Create the ModelCheckpoint callback\n","checkpoint_callback = ModelCheckpoint(checkpoint_path, save_weights_only=True, save_freq='epoch', period=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2nreRpPdDyXX","outputId":"a5c7361d-a4bd-4295-bfab-f73a9c769e7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","10/10 [==============================] - 12s 802ms/step - loss: 91.2736 - accuracy: 0.5500 - val_loss: 48.5879 - val_accuracy: 0.4000\n","Epoch 2/30\n","10/10 [==============================] - 7s 692ms/step - loss: 73.1823 - accuracy: 0.5813 - val_loss: 72.0743 - val_accuracy: 0.3750\n","Epoch 3/30\n","10/10 [==============================] - 7s 687ms/step - loss: 44.0801 - accuracy: 0.6000 - val_loss: 18.7626 - val_accuracy: 0.5750\n","Epoch 4/30\n","10/10 [==============================] - 7s 699ms/step - loss: 22.8797 - accuracy: 0.6750 - val_loss: 8.9953 - val_accuracy: 0.7750\n","Epoch 5/30\n","10/10 [==============================] - 7s 703ms/step - loss: 24.3453 - accuracy: 0.6438 - val_loss: 12.4218 - val_accuracy: 0.5750\n","Epoch 6/30\n","10/10 [==============================] - 7s 710ms/step - loss: 14.2535 - accuracy: 0.7000 - val_loss: 7.5190 - val_accuracy: 0.7500\n","Epoch 7/30\n","10/10 [==============================] - 7s 703ms/step - loss: 10.5501 - accuracy: 0.7063 - val_loss: 10.5226 - val_accuracy: 0.8000\n","Epoch 8/30\n","10/10 [==============================] - 7s 696ms/step - loss: 8.1606 - accuracy: 0.8313 - val_loss: 7.8591 - val_accuracy: 0.8000\n","Epoch 9/30\n","10/10 [==============================] - 7s 702ms/step - loss: 5.5295 - accuracy: 0.8250 - val_loss: 3.7349 - val_accuracy: 0.7750\n","Epoch 10/30\n","10/10 [==============================] - 7s 688ms/step - loss: 1.9533 - accuracy: 0.8687 - val_loss: 4.1300 - val_accuracy: 0.7750\n","Epoch 11/30\n","10/10 [==============================] - 7s 694ms/step - loss: 1.1532 - accuracy: 0.9187 - val_loss: 2.3579 - val_accuracy: 0.8250\n","Epoch 12/30\n","10/10 [==============================] - 7s 691ms/step - loss: 1.0352 - accuracy: 0.8625 - val_loss: 2.2806 - val_accuracy: 0.7250\n","Epoch 13/30\n","10/10 [==============================] - 7s 692ms/step - loss: 0.2214 - accuracy: 0.9438 - val_loss: 2.1006 - val_accuracy: 0.7250\n","Epoch 14/30\n","10/10 [==============================] - 7s 704ms/step - loss: 0.3987 - accuracy: 0.9375 - val_loss: 1.6672 - val_accuracy: 0.7500\n","Epoch 15/30\n","10/10 [==============================] - 7s 696ms/step - loss: 0.1997 - accuracy: 0.9625 - val_loss: 1.5319 - val_accuracy: 0.8000\n","Epoch 16/30\n","10/10 [==============================] - 8s 781ms/step - loss: 0.1478 - accuracy: 0.9438 - val_loss: 1.2565 - val_accuracy: 0.8750\n","Epoch 17/30\n","10/10 [==============================] - 8s 798ms/step - loss: 0.0910 - accuracy: 0.9625 - val_loss: 1.4586 - val_accuracy: 0.8000\n","Epoch 18/30\n","10/10 [==============================] - 7s 680ms/step - loss: 0.1937 - accuracy: 0.9563 - val_loss: 1.3240 - val_accuracy: 0.8250\n","Epoch 19/30\n","10/10 [==============================] - 7s 688ms/step - loss: 0.2030 - accuracy: 0.9563 - val_loss: 1.5558 - val_accuracy: 0.7750\n","Epoch 20/30\n","10/10 [==============================] - 7s 693ms/step - loss: 0.1546 - accuracy: 0.9563 - val_loss: 2.0437 - val_accuracy: 0.7250\n","Epoch 21/30\n","10/10 [==============================] - 7s 730ms/step - loss: 0.3575 - accuracy: 0.9500 - val_loss: 2.5393 - val_accuracy: 0.8750\n","Epoch 22/30\n","10/10 [==============================] - 7s 737ms/step - loss: 0.2651 - accuracy: 0.9688 - val_loss: 2.1752 - val_accuracy: 0.8500\n","Epoch 23/30\n","10/10 [==============================] - 7s 690ms/step - loss: 0.0786 - accuracy: 0.9563 - val_loss: 2.5764 - val_accuracy: 0.8250\n","Epoch 24/30\n","10/10 [==============================] - 8s 805ms/step - loss: 0.1152 - accuracy: 0.9625 - val_loss: 2.4704 - val_accuracy: 0.7500\n","Epoch 25/30\n","10/10 [==============================] - 8s 827ms/step - loss: 0.1445 - accuracy: 0.9625 - val_loss: 1.6983 - val_accuracy: 0.7500\n","Epoch 26/30\n","10/10 [==============================] - 7s 756ms/step - loss: 0.0776 - accuracy: 0.9563 - val_loss: 1.0903 - val_accuracy: 0.7250\n","Epoch 27/30\n","10/10 [==============================] - 7s 733ms/step - loss: 0.0792 - accuracy: 0.9500 - val_loss: 1.0340 - val_accuracy: 0.8000\n","Epoch 28/30\n","10/10 [==============================] - 7s 763ms/step - loss: 0.0715 - accuracy: 0.9625 - val_loss: 1.7078 - val_accuracy: 0.6750\n","Epoch 29/30\n","10/10 [==============================] - 8s 807ms/step - loss: 0.0822 - accuracy: 0.9500 - val_loss: 1.5008 - val_accuracy: 0.7500\n","Epoch 30/30\n","10/10 [==============================] - 7s 745ms/step - loss: 0.1019 - accuracy: 0.9312 - val_loss: 1.6815 - val_accuracy: 0.7500\n"]}],"source":["history = model.fit(\n","  train_ds,\n","  validation_data = val_ds,\n","  epochs=30,\n","  batch_size=16,\n","  callbacks = checkpoint_callback)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5GWwFDuDyXY"},"outputs":[],"source":["from matplotlib import pyplot\n","import sys\n","\n","# plot diagnostic learning curves\n","def summarize_diagnostics(history):\n","\t# plot loss\n","\tpyplot.subplot(211)\n","\tpyplot.title('Cross Entropy Loss')\n","\tpyplot.plot(history.history['loss'], color='blue', label='train')\n","\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n","\t# plot accuracy\n","\tpyplot.subplot(212)\n","\tpyplot.title('Classification Accuracy')\n","\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n","\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n","\tpyplot.tight_layout()\n","\t# save plot to file\n","\tfilename = sys.argv[0].split('/')[-1]\n","\tpyplot.savefig(filename + '_plot.png')\n","\tpyplot.close()\n","\n","summarize_diagnostics(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-s3Zp9b1DyXY","outputId":"f926338f-eef8-46ba-e317-bb7e83856ef1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 200 files belonging to 2 classes.\n","13/13 [==============================] - 1s 45ms/step - loss: 1.4372e-04 - accuracy: 1.0000\n"]},{"data":{"text/plain":["[0.00014371922588907182, 1.0]"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["\n","val_ds = tf.keras.utils.image_dataset_from_directory(\n","  file_dir,\n","  image_size= (512, 640),\n","  label_mode = 'categorical',\n","  color_mode = \"grayscale\",\n","  batch_size=batch_size)\n","\n","model.evaluate(val_ds)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wDY9eyNpPw-i","outputId":"86ddb4a7-3d4c-4aac-aee2-c6eba1bbb543"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GIoNwkarYasr","outputId":"e717d737-0fc4-46bd-9ade-f6417de04d90"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_6 (InputLayer)        [(None, 512, 640, 1)]     0         \n","                                                                 \n"," lambda_2 (Lambda)           (None, 512, 640, 3)       0         \n","                                                                 \n"," resnet101 (Functional)      (None, 16, 20, 2048)      42658176  \n","                                                                 \n"," flatten_2 (Flatten)         (None, 655360)            0         \n","                                                                 \n"," dense_8 (Dense)             (None, 256)               167772416 \n","                                                                 \n"," dropout_6 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_9 (Dense)             (None, 128)               32896     \n","                                                                 \n"," dropout_7 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_10 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout_8 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_11 (Dense)            (None, 2)                 130       \n","                                                                 \n","=================================================================\n","Total params: 210,471,874\n","Trainable params: 167,813,698\n","Non-trainable params: 42,658,176\n","_________________________________________________________________\n"]}],"source":["# model.save('/content/drive/MyDrive/simpler.h5')\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"GorOKGj2Y2xL","outputId":"5933ade4-e767-4bc0-b295-13333ef7e54b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/model_checkpoint_21.h5'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":24}],"source":["import shutil\n","\n","# Define the source and destination paths\n","source_path = \"/content/model_checkpoint_21.h5\"\n","destination_path = \"/content/drive/MyDrive/model_checkpoint_21.h5\"\n","\n","# Move the file\n","shutil.move(source_path, destination_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DuO14bvr5_id"},"outputs":[],"source":["model.save('/content/drive/MyDrive/resnet101_set1.h5')\n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}